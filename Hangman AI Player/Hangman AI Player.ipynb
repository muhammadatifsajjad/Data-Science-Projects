{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modelling in Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author: Muhammad Atif\n",
    "\n",
    "Python version used: 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Overview</b>: Development of an 'artificial intelligence' player for the classic Hangman word guessing game by implementing several different automatic strategies based on character level language models, ranging from unigram approaches to higher order n-gram models. Objective is to create an automatic player which makes the fewest mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hangman Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <a href=\"https://en.wikipedia.org/wiki/Hangman_(game)\">Hangman game</a> is a simple game whereby one person thinks of a word, which they keep secret from their opponent, who tries to guess the word one character at a time. The game ends when the opponent makes more than a fixed number of incorrect guesses, or they figure out the secret word before then (in which case they *win*). \n",
    "\n",
    "Here's a simple version of the game, and a method allowing interactive play. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allowing better python 2 & python 3 compatibility \n",
    "from __future__ import print_function \n",
    "\n",
    "def hangman(secret_word, guesser, max_mistakes=8, verbose=True, **guesser_args):\n",
    "    \"\"\"\n",
    "        secret_word: a string of lower-case alphabetic characters, i.e., the answer to the game\n",
    "        guesser: a function which guesses the next character at each stage in the game\n",
    "            The function takes a:\n",
    "                mask: what is known of the word, as a string with _ denoting an unknown character\n",
    "                guessed: the set of characters which already been guessed in the game\n",
    "                guesser_args: additional (optional) keyword arguments, i.e., name=value\n",
    "        max_mistakes: limit on length of game, in terms of allowed mistakes\n",
    "        verbose: be chatty vs silent\n",
    "        guesser_args: keyword arguments to pass directly to the guesser function\n",
    "    \"\"\"\n",
    "    secret_word = secret_word.lower()\n",
    "    mask = ['_'] * len(secret_word)\n",
    "    guessed = set()\n",
    "    if verbose:\n",
    "        print(\"Starting hangman game. Target is\", ' '.join(mask), 'length', len(secret_word))\n",
    "    \n",
    "    mistakes = 0\n",
    "    while mistakes < max_mistakes:\n",
    "        if verbose:\n",
    "            print(\"You have\", (max_mistakes-mistakes), \"attempts remaining.\")\n",
    "        guess = guesser(mask, guessed, **guesser_args)\n",
    "\n",
    "        if verbose:\n",
    "            print('Guess is', guess)\n",
    "        if guess in guessed:\n",
    "            if verbose:\n",
    "                print('Already guessed this before.')\n",
    "            mistakes += 1\n",
    "        else:\n",
    "            guessed.add(guess)\n",
    "            if guess in secret_word:\n",
    "                for i, c in enumerate(secret_word):\n",
    "                    if c == guess:\n",
    "                        mask[i] = c\n",
    "                if verbose:\n",
    "                    print('Good guess:', ' '.join(mask))\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('Sorry, try again.')\n",
    "                mistakes += 1\n",
    "                \n",
    "        if '_' not in mask:\n",
    "            if verbose:\n",
    "                print('Congratulations, you won.')\n",
    "            return mistakes\n",
    "        \n",
    "    if verbose:\n",
    "        print('Out of guesses. The word was', secret_word)    \n",
    "    return mistakes\n",
    "\n",
    "def human(mask, guessed, **kwargs):\n",
    "    \"\"\"\n",
    "    simple function for manual play\n",
    "    \"\"\"\n",
    "    print('Enter your guess:')\n",
    "    try:\n",
    "        return raw_input().lower().strip() # python 3\n",
    "    except NameError:\n",
    "        return input().lower().strip() # python 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game can be played interactively using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hangman game. Target is _ _ _ _ _ _ _ _ length 8\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "w\n",
      "Guess is w\n",
      "Good guess: w _ _ _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "h\n",
      "Guess is h\n",
      "Good guess: w h _ _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "a\n",
      "Guess is a\n",
      "Good guess: w h a _ _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "t\n",
      "Guess is t\n",
      "Good guess: w h a t _ _ _ _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Good guess: w h a t e _ e _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "v\n",
      "Guess is v\n",
      "Good guess: w h a t e v e _\n",
      "You have 8 attempts remaining.\n",
      "Enter your guess:\n",
      "e\n",
      "Guess is e\n",
      "Already guessed this before.\n",
      "You have 7 attempts remaining.\n",
      "Enter your guess:\n",
      "r\n",
      "Guess is r\n",
      "Good guess: w h a t e v e r\n",
      "Congratulations, you won.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hangman('whatever', human, 8, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<b>Instructions</b>: We will be using the words occurring in the *Brown* corpus for *training* an artificial intelligence guessing algorithm, and for *evaluating* the quality of the method. Note that we are intentionally making the hangman game hard, as the AI will need to cope with test words that it has not seen before, hence it will need to learn generalisable patterns of characters to make reasonable predictions.\n",
    "\n",
    "First task is to compute the unique word types occurring in the *Brown* corpus, selecting only words that are entirely comprised of alphabetic characters, and lowercasing the words. Finally, randomly shuffle this collection of word types, and split them into disjoint training and testing sets. The test set should contain 1000 word types, and the rest should be in the training set.\n",
    "\n",
    "Feel free to test Hangman performance using `hangman(numpy.random.choice(test_set), human, 8, True)`. It is surprisingly difficult (and addictive)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of word types in Test Set:  1000\n",
      "Number of word types in Train Set:  39234\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import brown   \n",
    "\n",
    "# unique word types of lower-cased, alphabetic characters from brown corpus\n",
    "wordTypes = set()\n",
    "for words in brown.words():\n",
    "    word = words.lower()\n",
    "    if word.isalpha():\n",
    "        wordTypes.add(word)       \n",
    "uniqueWordTypes = list(wordTypes)\n",
    "\n",
    "# randomly shuffle word types and split in train and test sets\n",
    "np.random.shuffle(uniqueWordTypes)\n",
    "testSet = uniqueWordTypes[0:1000]\n",
    "trainSet = uniqueWordTypes[1000:]\n",
    "\n",
    "# print size of train and test sets\n",
    "print(\"Number of word types in Test Set: \", len(testSet))\n",
    "print(\"Number of word types in Train Set: \", len(trainSet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set a baseline, our first *AI* attempt will be a trivial random method. For this we will implement a guessing method, similar to the `human` method above, i.e., using the same input arguments and returning a character. Our method will randomly choose a character from the range `'a'...'z'` after excluding the characters that have already been guessed in the current game (all subsequent AI approaches will also exclude previous guesses).\n",
    "\n",
    "To measure the performance of this (and later) techiques, we will implement a method that measures the average number of mistakes made by this technique over all the words in the `test_set`. Print the average number of mistakes for the random AI, which will become a baseline for the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of mistakes for random guesser:  16.709\n"
     ]
    }
   ],
   "source": [
    "# randomly return an alphabet which has not already been guessed\n",
    "def randomGuesser(mask, guessed, **kwargs):\n",
    "    alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "             'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "    alphabets = alphabets - guessed \n",
    "    return np.random.choice(list(alphabets))\n",
    "\n",
    "# return average number of mistakes made by a given model in solving hangman across entire list of words\n",
    "def hangmanPerformance(listOfWords, method, **kwargs):\n",
    "    totalNoOfMistakes = 0\n",
    "    for word in listOfWords:\n",
    "        totalNoOfMistakes += hangman(word, method, 26, False, **kwargs)  \n",
    "    return(totalNoOfMistakes / len(listOfWords))\n",
    "\n",
    "print('Average number of mistakes for random guesser: ', hangmanPerformance(testSet, randomGuesser))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our first real AI, we will train a *unigram* model over the training set. This will require to find the frequencies of characters over all training words. Using this model, we will write a guess function that returns the character with the highest probability, after aggregating (summing) the probability of each blank character in the secret word. Print the average number of mistakes the unigram method makes over the test set. We will exclude already guessed characters, and use the same evaluation method as above, so the results are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of mistakes for unigram guesser:  10.211\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# build alphabet frequency dictionary\n",
    "totalCharacters = 0\n",
    "charFreqDict = {}\n",
    "for words in trainSet:\n",
    "    for character in words:\n",
    "        charFreqDict[character] = charFreqDict.get(character, 0) + 1 \n",
    "        totalCharacters += 1              \n",
    "\n",
    "# convert character frequency into probability                 \n",
    "for alphabet in charFreqDict:\n",
    "    charFreqDict[alphabet] = charFreqDict[alphabet] / totalCharacters\n",
    "\n",
    "# store ordered list of alphabets based on frequency in descending order\n",
    "charFreqDict = sorted(charFreqDict.items(), key=operator.itemgetter(1), reverse=True) \n",
    "orderedCharsList = []\n",
    "for characters in charFreqDict:\n",
    "    orderedCharsList.append(characters[0])\n",
    "\n",
    "# return an alphabet with highest probability across all alphabets (appearing in words) in train set\n",
    "def unigramGuesser(mask, guessed, **kwargs):\n",
    "    remCharsList = [chars for chars in orderedCharsList if chars not in guessed]\n",
    "    return remCharsList[0]\n",
    "\n",
    "print('Average number of mistakes for unigram guesser: ', hangmanPerformance(testSet, unigramGuesser))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The length of the secret word is an important clue that we might exploit. Different length words tend to have different distributions over characters, e.g., short words are less likely to have suffixes or prefixes. We will now incorporate this idea by conditioning the unigram model on the length of the secret word, i.e., having *different* unigram models for each length of word. We will need to be a little careful at test time, to be robust to the (unlikely) situation that we might encounter a word length that we didn't see in training. Let's create another AI guessing function using this new model, and print its test performance.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of mistakes for length conditioned unigram guesser:  10.213\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "# get total number of different length words\n",
    "lenOfWords=[]\n",
    "for words in trainSet:\n",
    "    lenOfWords.append(len(words))\n",
    "wordLengthCounts = Counter(lenOfWords)\n",
    "\n",
    "# get total count of alphabets for given length of word\n",
    "charFreqDictByLength = {}\n",
    "for words in trainSet:\n",
    "    for character in words:\n",
    "        charFreqDictByLength[character, len(words)] = charFreqDictByLength.get((character, len(words)),0) + 1\n",
    "\n",
    "# convert alphabet frequencies per word length into probabilities, as follows:\n",
    "# P(alphabet | wordLength) = (number of times an alphabet appeared in a word length) / (number of total alphabets across all words in that word length)\n",
    "for a in charFreqDictByLength:\n",
    "    charFreqDictByLength[a[0], a[1]] = charFreqDictByLength.get((a[0], a[1]), 0) / (a[1] * wordLengthCounts[a[1]])\n",
    "\n",
    "# return probability given an alphabet and word length\n",
    "# if alphabet, wordlength pair is not found check recursively in wordlength-1 \n",
    "# until a pair is found or wordlength becomes 0\n",
    "def getCharProbGivenLength(char,length):\n",
    "    if length == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        if (char, length) in charFreqDictByLength:\n",
    "            return charFreqDictByLength[char, length]\n",
    "        else:\n",
    "            return getCharProbGivenLength(char, length-1)\n",
    "\n",
    "# return an alphabet with highest probability across all alphabets appearing in words of the same length as the secret word in train set\n",
    "def lengthCondUnigramGuesser(mask, guessed):\n",
    "    alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "             'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])    \n",
    "    alphabets = alphabets - guessed \n",
    "    maskLength = len(mask)\n",
    "    maxFreq = (-1,'_')\n",
    "    for char in alphabets:\n",
    "       if getCharProbGivenLength(char,maskLength) > maxFreq[0]:\n",
    "        maxFreq = (getCharProbGivenLength(char,maskLength),char)\n",
    "    return maxFreq[1]\n",
    "\n",
    "print('Average number of mistakes for length conditioned unigram guesser: ', hangmanPerformance(testSet, lengthCondUnigramGuesser))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the main challenge, using a *ngram* language model over characters. The order of characters is obviously important, yet this wasn't incorporated in any of the above models. Knowing that the word has the sequence `n _ s s` is a pretty strong clue that the missing character might be `e`. Similarly the distribution over characters that start or end a word are highly biased (e.g., toward common prefixes and suffixes, like *un-*, *-ed* and *-ly*).\n",
    "\n",
    "We will now develop a *ngram* language model over characters, train this over the training words (being careful to handle the start of each word properly, e.g., by padding with sentinel symbols.) We will use linear interpolation to smooth between the higher order and lower order models, and will have to decide how to weight each component. \n",
    "\n",
    "The guessing AI algorithm should apply the language model to each blank position in the secret word by using as much of the left context as is known. E.g., in `_ e c _ e _ _` we know the full left context for the first blank (context=start of word), we have a context of two characters for the second blank (context=ec), one character for the second last blank (context=e), and no known context for the last one. If we were using a *n=3* order model, we would be able to apply it to the first and second blanks, but would only be able to use the bigram or unigram distributions for the subsequent blanks. As with the unigram model, you should sum over the probability distributions for each blank to find the expected count for each character type, then select the  character with the highest expected count.\n",
    "\n",
    "We will implement the ngram method for *n=3,4* and *5* and evaluate each of these three models over the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of mistakes for trigram guesser:  8.341\n",
      "Average number of mistakes for quadgram guesser:  7.837\n",
      "Average number of mistakes for pentgram guesser:  7.649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "def convertWord(word):\n",
    "    return [\"<s>\",\"<s>\",\"<s>\",\"<s>\"] + [alphabet for alphabet in word] + [\"</s>\"]\n",
    "\n",
    "def getNgramProb(dataset):\n",
    "    # initialize variables\n",
    "    unigramProb = Counter()\n",
    "    bigramProb = defaultdict(Counter)\n",
    "    trigramProb = defaultdict(lambda: defaultdict(Counter))\n",
    "    quadgramProb = defaultdict(lambda: defaultdict(lambda: defaultdict(Counter)))\n",
    "    pentgramProb = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(Counter))))\n",
    "\n",
    "    # collect unigram counts\n",
    "    for word in dataset:\n",
    "        word = convertWord(word)\n",
    "        for alphabet in word:\n",
    "            unigramProb[alphabet] += 1\n",
    "        unigramProb[\"</s>\"] += 1\n",
    "    \n",
    "    # using alphabet frequency, compute probability of a given alphabet across all alphabets (appearing in words) in train set\n",
    "    for alphabet in unigramProb:\n",
    "        unigramProb[alphabet] = unigramProb[alphabet] / totalCharacters\n",
    "    \n",
    "    # collect bigram counts\n",
    "    for word in dataset:\n",
    "        word = convertWord(word)\n",
    "        # generate a list of bigrams\n",
    "        bigram1 = [word[i] for i in range(len(word)-1)]\n",
    "        bigram2 = [word[i+1] for i in range(len(word)-1)]\n",
    "        bigramList = zip(bigram1, bigram2)\n",
    "        # iterate over bigrams\n",
    "        for bigram in bigramList:\n",
    "            first, second = bigram\n",
    "            bigramProb[first][second] += 1\n",
    "    \n",
    "    # compute probability for second alphabet given first alphabet\n",
    "    for first in bigramProb:\n",
    "        for second in bigramProb[first]:\n",
    "            bigramProb[first][second] = bigramProb[first][second] / sum(bigramProb[first].values())\n",
    "\n",
    "    # collect trigram counts\n",
    "    for word in dataset:\n",
    "        word = convertWord(word)\n",
    "        # generate a list of trigrams\n",
    "        trigram1 = [word[i] for i in range(len(word)-2)]\n",
    "        trigram2 = [word[i+1] for i in range(len(word)-2)]\n",
    "        trigram3 = [word[i+2] for i in range(len(word)-2)]\n",
    "        trigramList = zip(trigram1, trigram2, trigram3)\n",
    "        # iterate over trigrams\n",
    "        for trigram in trigramList:\n",
    "            first, second, third = trigram\n",
    "            trigramProb[first][second][third] += 1\n",
    "    \n",
    "    # compute probability for third alphabet given first and second alphabets\n",
    "    for first in trigramProb:\n",
    "        for second in trigramProb[first]:\n",
    "            bigramCount = sum(trigramProb[first][second].values())\n",
    "            for third in trigramProb[first][second]:\n",
    "                trigramProb[first][second][third] = trigramProb[first][second][third] / bigramCount\n",
    "\n",
    "    # collect quadgram counts\n",
    "    for word in dataset:\n",
    "        word = convertWord(word)\n",
    "        # generate a list of quadgrams\n",
    "        quadgram1 = [word[i] for i in range(len(word)-3)]\n",
    "        quadgram2 = [word[i+1] for i in range(len(word)-3)]\n",
    "        quadgram3 = [word[i+2] for i in range(len(word)-3)]\n",
    "        quadgram4 = [word[i+3] for i in range(len(word)-3)]\n",
    "        quadgramList = zip(quadgram1, quadgram2, quadgram3, quadgram4)\n",
    "        # iterate over trigrams\n",
    "        for quadgram in quadgramList:\n",
    "            first, second, third, fourth = quadgram\n",
    "            quadgramProb[first][second][third][fourth] += 1\n",
    "    \n",
    "    # compute probability for fourth alphabet given first, second, and third alphabets\n",
    "    for first in quadgramProb:\n",
    "        for second in quadgramProb[first]:\n",
    "            for third in quadgramProb[first][second]:\n",
    "                trigramCount = sum(quadgramProb[first][second][third].values())\n",
    "                for fourth in quadgramProb[first][second][third]:\n",
    "                    quadgramProb[first][second][third][fourth] = quadgramProb[first][second][third][fourth] / trigramCount\n",
    "        \n",
    "    # collect pentgram counts\n",
    "    for word in dataset:\n",
    "        word = convertWord(word)\n",
    "        # generate a list of quadgrams\n",
    "        pentgram1 = [word[i] for i in range(len(word)-4)]\n",
    "        pentgram2 = [word[i+1] for i in range(len(word)-4)]\n",
    "        pentgram3 = [word[i+2] for i in range(len(word)-4)]\n",
    "        pentgram4 = [word[i+3] for i in range(len(word)-4)]\n",
    "        pentgram5 = [word[i+4] for i in range(len(word)-4)]\n",
    "        pentgramList = zip(pentgram1, pentgram2, pentgram3, pentgram4, pentgram5)\n",
    "        # iterate over trigrams\n",
    "        for pentgram in pentgramList:\n",
    "            first, second, third, fourth, fifth = pentgram\n",
    "            pentgramProb[first][second][third][fourth][fifth] += 1\n",
    "    \n",
    "    # compute probability for fifth alphabet given first, second, third, and fourth alphabets\n",
    "    for first in pentgramProb:\n",
    "        for second in pentgramProb[first]:\n",
    "            for third in pentgramProb[first][second]:\n",
    "                for fourth in pentgramProb[first][second][third]:\n",
    "                    quadgramCount = sum(pentgramProb[first][second][third][fourth].values())\n",
    "                    for fifth in pentgramProb[first][second][third][fourth]:\n",
    "                        pentgramProb[first][second][third][fourth][fifth] = pentgramProb[first][second][third][fourth][fifth] / quadgramCount\n",
    "\n",
    "    return(unigramProb, bigramProb, trigramProb, quadgramProb, pentgramProb)\n",
    "\n",
    "# get probabilities for unigram, bigram, trigram, quadgram, and pentgram\n",
    "unigramProb, bigramProb, trigramProb, quadgramProb, pentgramProb = getNgramProb(trainSet)\n",
    "\n",
    "def trigramGuesser(mask, guessed, **kwargs):\n",
    "    # initialize variables\n",
    "    uniProb = defaultdict(Counter)\n",
    "    biProb = defaultdict(Counter) \n",
    "    triProb = defaultdict(Counter) \n",
    "    interpProb = defaultdict(Counter) \n",
    "    alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "         'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "    alphabets = alphabets - guessed \n",
    "    mask = [\"<s>\",\"<s>\"] + [char for char in mask]\n",
    "    maskLength = len(mask)\n",
    "    \n",
    "    # get unigram, bigram, and trigram probabilities for each position\n",
    "    for pos in range(2, maskLength):\n",
    "        if (mask[pos] == '_'):\n",
    "            for alphabet in alphabets:\n",
    "                uniProb[pos][alphabet] = unigramProb[alphabet]\n",
    "                biProb[pos][alphabet] = bigramProb[mask[pos-1]][alphabet]\n",
    "                triProb[pos][alphabet] = trigramProb[mask[pos-2]][mask[pos-1]][alphabet]\n",
    "    \n",
    "    # parameters for linear interpolation\n",
    "    lambdaUnigram = kwargs['lambdaUnigram']\n",
    "    lambdaBigram = kwargs['lambdaBigram']\n",
    "    lambdaTrigram = 1 - lambdaUnigram - lambdaBigram\n",
    "    \n",
    "    # sum all the vector of probabilities over each alphabet, to get a vector of scores for each alphabet     \n",
    "    for alphabet in alphabets:\n",
    "        interpProb[alphabet] = 0\n",
    "        for pos in uniProb:\n",
    "            interpProb[alphabet] += (lambdaUnigram * uniProb[pos][alphabet]) + (lambdaBigram * biProb[pos][alphabet]) + (lambdaTrigram * triProb[pos][alphabet])\n",
    "    \n",
    "    # return the alphabet which has the highest score\n",
    "    return(max(interpProb, key=interpProb.get))    \n",
    "        \n",
    "print('Average number of mistakes for trigram guesser: ', hangmanPerformance(testSet, trigramGuesser, lambdaUnigram=0.1, lambdaBigram=0.0))  \n",
    "\n",
    "def quadgramGuesser(mask, guessed, **kwargs):\n",
    "    # initialize variables\n",
    "    uniProb = defaultdict(Counter)\n",
    "    biProb = defaultdict(Counter) \n",
    "    triProb = defaultdict(Counter) \n",
    "    quadProb = defaultdict(Counter) \n",
    "    interpProb = defaultdict(Counter) \n",
    "    alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "         'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "    alphabets = alphabets - guessed \n",
    "    mask = [\"<s>\",\"<s>\",\"<s>\"] + [char for char in mask]\n",
    "    maskLength = len(mask)\n",
    "    \n",
    "    # get unigram, bigram, trigram, and quadgram probabilities for each position\n",
    "    for pos in range(3, maskLength):\n",
    "        if (mask[pos] == '_'):\n",
    "            for alphabet in alphabets:\n",
    "                uniProb[pos][alphabet] = unigramProb[alphabet]\n",
    "                biProb[pos][alphabet] = bigramProb[mask[pos-1]][alphabet]\n",
    "                triProb[pos][alphabet] = trigramProb[mask[pos-2]][mask[pos-1]][alphabet]\n",
    "                quadProb[pos][alphabet] = quadgramProb[mask[pos-3]][mask[pos-2]][mask[pos-1]][alphabet]\n",
    "\n",
    "    # parameters for linear interpolation\n",
    "    lambdaUnigram = kwargs['lambdaUnigram']\n",
    "    lambdaBigram = kwargs['lambdaBigram']\n",
    "    lambdaTrigram = kwargs['lambdaTrigram']\n",
    "    lambdaQuadgram = 1 - lambdaUnigram - lambdaBigram - lambdaTrigram\n",
    "    \n",
    "    # sum all the vector of probabilities over each alphabet, to get a vector of scores for each alphabet   \n",
    "    for alphabet in alphabets:\n",
    "        interpProb[alphabet] = 0\n",
    "        for pos in uniProb:\n",
    "            interpProb[alphabet] += (lambdaUnigram * uniProb[pos][alphabet]) + (lambdaBigram * biProb[pos][alphabet]) + (lambdaTrigram * triProb[pos][alphabet]) + (lambdaQuadgram * quadProb[pos][alphabet])\n",
    "\n",
    "    # return the alphabet which has the highest score\n",
    "    return(max(interpProb, key=interpProb.get))    \n",
    "\n",
    "print('Average number of mistakes for quadgram guesser: ', hangmanPerformance(testSet, quadgramGuesser, lambdaUnigram=0.1, lambdaBigram=0.0, lambdaTrigram=0.3))  \n",
    "\n",
    "def pentgramGuesser(mask, guessed, **kwargs):\n",
    "    # initialize variables\n",
    "    uniProb = defaultdict(Counter)\n",
    "    biProb = defaultdict(Counter) \n",
    "    triProb = defaultdict(Counter) \n",
    "    quadProb = defaultdict(Counter) \n",
    "    pentProb = defaultdict(Counter) \n",
    "    interpProb = defaultdict(Counter) \n",
    "    alphabets = set(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "         'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "    alphabets = alphabets - guessed \n",
    "    mask = [\"<s>\",\"<s>\",\"<s>\",\"<s>\"] + [char for char in mask]\n",
    "    maskLength = len(mask)\n",
    "    \n",
    "    # get unigram, bigram, trigram, quadgram, and pentgram probabilities for each position\n",
    "    for pos in range(4, maskLength):\n",
    "        if (mask[pos] == '_'):\n",
    "            for alphabet in alphabets:\n",
    "                uniProb[pos][alphabet] = unigramProb[alphabet]\n",
    "                biProb[pos][alphabet] = bigramProb[mask[pos-1]][alphabet]\n",
    "                triProb[pos][alphabet] = trigramProb[mask[pos-2]][mask[pos-1]][alphabet]\n",
    "                quadProb[pos][alphabet] = quadgramProb[mask[pos-3]][mask[pos-2]][mask[pos-1]][alphabet]\n",
    "                pentProb[pos][alphabet] = pentgramProb[mask[pos-4]][mask[pos-3]][mask[pos-2]][mask[pos-1]][alphabet]\n",
    "\n",
    "    # parameters for linear interpolation\n",
    "    lambdaUnigram = kwargs['lambdaUnigram']\n",
    "    lambdaBigram = kwargs['lambdaBigram']\n",
    "    lambdaTrigram = kwargs['lambdaTrigram']\n",
    "    lambdaQuadgram = kwargs['lambdaQuadgram']\n",
    "    lambdaPentgram = 1 - lambdaUnigram - lambdaBigram - lambdaTrigram - lambdaQuadgram\n",
    "    \n",
    "    # sum all the vector of probabilities over each alphabet, to get a vector of scores for each alphabet       \n",
    "    for alphabet in alphabets:\n",
    "        interpProb[alphabet] = 0\n",
    "        for pos in uniProb:\n",
    "            interpProb[alphabet] += (lambdaUnigram * uniProb[pos][alphabet]) + (lambdaBigram * biProb[pos][alphabet]) + (lambdaTrigram * triProb[pos][alphabet]) + (lambdaQuadgram * quadProb[pos][alphabet]) + (lambdaPentgram * pentProb[pos][alphabet])\n",
    "\n",
    "    # return the alphabet which has the highest score    \n",
    "    return(max(interpProb, key=interpProb.get))    \n",
    "\n",
    "print('Average number of mistakes for pentgram guesser: ', hangmanPerformance(testSet, pentgramGuesser, lambdaUnigram=0.1, lambdaBigram=0.0, lambdaTrigram=0.2, lambdaQuadgram=0.1))  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
